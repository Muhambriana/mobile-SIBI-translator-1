{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the much needed stuff for training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-building",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_fingerX</th>\n",
       "      <th>thumb_fingerY</th>\n",
       "      <th>index_fingerX</th>\n",
       "      <th>index_fingerY</th>\n",
       "      <th>middle_fingerX</th>\n",
       "      <th>middle_fingerY</th>\n",
       "      <th>ring_fingerX</th>\n",
       "      <th>ring_fingerY</th>\n",
       "      <th>pinky_fingerX</th>\n",
       "      <th>pinky_fingerY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>698.883772</td>\n",
       "      <td>319.741607</td>\n",
       "      <td>910.551667</td>\n",
       "      <td>867.297888</td>\n",
       "      <td>1027.874112</td>\n",
       "      <td>1007.115364</td>\n",
       "      <td>1132.986546</td>\n",
       "      <td>1166.618705</td>\n",
       "      <td>1292.077541</td>\n",
       "      <td>1233.430743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>741.502106</td>\n",
       "      <td>542.201161</td>\n",
       "      <td>887.608528</td>\n",
       "      <td>981.449902</td>\n",
       "      <td>1010.184288</td>\n",
       "      <td>1085.316420</td>\n",
       "      <td>1105.530739</td>\n",
       "      <td>1191.878557</td>\n",
       "      <td>1239.938617</td>\n",
       "      <td>1190.378189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>647.951245</td>\n",
       "      <td>386.042297</td>\n",
       "      <td>868.203998</td>\n",
       "      <td>938.034773</td>\n",
       "      <td>987.109005</td>\n",
       "      <td>1075.520873</td>\n",
       "      <td>1089.050293</td>\n",
       "      <td>1230.622411</td>\n",
       "      <td>1244.453907</td>\n",
       "      <td>1303.694963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>695.430517</td>\n",
       "      <td>385.009110</td>\n",
       "      <td>796.478271</td>\n",
       "      <td>821.513295</td>\n",
       "      <td>966.983616</td>\n",
       "      <td>911.345065</td>\n",
       "      <td>1098.146200</td>\n",
       "      <td>1029.722214</td>\n",
       "      <td>1272.009134</td>\n",
       "      <td>1037.135959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>678.814888</td>\n",
       "      <td>382.618010</td>\n",
       "      <td>777.017236</td>\n",
       "      <td>821.001649</td>\n",
       "      <td>949.144900</td>\n",
       "      <td>903.855205</td>\n",
       "      <td>1082.251310</td>\n",
       "      <td>1025.459528</td>\n",
       "      <td>1254.212260</td>\n",
       "      <td>1040.963411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Z</td>\n",
       "      <td>1300.618052</td>\n",
       "      <td>1258.664370</td>\n",
       "      <td>1416.399121</td>\n",
       "      <td>763.170362</td>\n",
       "      <td>1489.546895</td>\n",
       "      <td>521.581769</td>\n",
       "      <td>967.163205</td>\n",
       "      <td>1347.211719</td>\n",
       "      <td>1000.565648</td>\n",
       "      <td>1386.885405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Z</td>\n",
       "      <td>1246.104598</td>\n",
       "      <td>1362.797260</td>\n",
       "      <td>1441.542387</td>\n",
       "      <td>888.679862</td>\n",
       "      <td>1335.812926</td>\n",
       "      <td>782.377422</td>\n",
       "      <td>931.693971</td>\n",
       "      <td>1396.972418</td>\n",
       "      <td>962.328613</td>\n",
       "      <td>1413.898706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Z</td>\n",
       "      <td>1237.197399</td>\n",
       "      <td>1307.267547</td>\n",
       "      <td>1640.771866</td>\n",
       "      <td>511.455238</td>\n",
       "      <td>1013.165593</td>\n",
       "      <td>1168.433547</td>\n",
       "      <td>991.639078</td>\n",
       "      <td>1238.492608</td>\n",
       "      <td>1158.645153</td>\n",
       "      <td>1050.116062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Z</td>\n",
       "      <td>1150.378823</td>\n",
       "      <td>1380.880356</td>\n",
       "      <td>1494.812250</td>\n",
       "      <td>482.839018</td>\n",
       "      <td>839.623094</td>\n",
       "      <td>1195.330620</td>\n",
       "      <td>893.580377</td>\n",
       "      <td>1250.582814</td>\n",
       "      <td>964.640975</td>\n",
       "      <td>1202.009916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Z</td>\n",
       "      <td>1243.302226</td>\n",
       "      <td>1331.760645</td>\n",
       "      <td>1486.740589</td>\n",
       "      <td>463.822871</td>\n",
       "      <td>917.246103</td>\n",
       "      <td>1146.457553</td>\n",
       "      <td>940.406561</td>\n",
       "      <td>1271.361947</td>\n",
       "      <td>1063.025475</td>\n",
       "      <td>1089.760184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_type  thumb_fingerX  thumb_fingerY  index_fingerX  index_fingerY  \\\n",
       "0            A     698.883772     319.741607     910.551667     867.297888   \n",
       "1            A     741.502106     542.201161     887.608528     981.449902   \n",
       "2            A     647.951245     386.042297     868.203998     938.034773   \n",
       "3            A     695.430517     385.009110     796.478271     821.513295   \n",
       "4            A     678.814888     382.618010     777.017236     821.001649   \n",
       "..         ...            ...            ...            ...            ...   \n",
       "456          Z    1300.618052    1258.664370    1416.399121     763.170362   \n",
       "457          Z    1246.104598    1362.797260    1441.542387     888.679862   \n",
       "458          Z    1237.197399    1307.267547    1640.771866     511.455238   \n",
       "459          Z    1150.378823    1380.880356    1494.812250     482.839018   \n",
       "460          Z    1243.302226    1331.760645    1486.740589     463.822871   \n",
       "\n",
       "     middle_fingerX  middle_fingerY  ring_fingerX  ring_fingerY  \\\n",
       "0       1027.874112     1007.115364   1132.986546   1166.618705   \n",
       "1       1010.184288     1085.316420   1105.530739   1191.878557   \n",
       "2        987.109005     1075.520873   1089.050293   1230.622411   \n",
       "3        966.983616      911.345065   1098.146200   1029.722214   \n",
       "4        949.144900      903.855205   1082.251310   1025.459528   \n",
       "..              ...             ...           ...           ...   \n",
       "456     1489.546895      521.581769    967.163205   1347.211719   \n",
       "457     1335.812926      782.377422    931.693971   1396.972418   \n",
       "458     1013.165593     1168.433547    991.639078   1238.492608   \n",
       "459      839.623094     1195.330620    893.580377   1250.582814   \n",
       "460      917.246103     1146.457553    940.406561   1271.361947   \n",
       "\n",
       "     pinky_fingerX  pinky_fingerY  \n",
       "0      1292.077541    1233.430743  \n",
       "1      1239.938617    1190.378189  \n",
       "2      1244.453907    1303.694963  \n",
       "3      1272.009134    1037.135959  \n",
       "4      1254.212260    1040.963411  \n",
       "..             ...            ...  \n",
       "456    1000.565648    1386.885405  \n",
       "457     962.328613    1413.898706  \n",
       "458    1158.645153    1050.116062  \n",
       "459     964.640975    1202.009916  \n",
       "460    1063.025475    1089.760184  \n",
       "\n",
       "[461 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read CSV file for Training the model using Pandas\n",
    "df_train = pd.read_csv(\"hands_SIBI_training.csv\", header=0)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaptive-surgery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_fingerX</th>\n",
       "      <th>thumb_fingerY</th>\n",
       "      <th>index_fingerX</th>\n",
       "      <th>index_fingerY</th>\n",
       "      <th>middle_fingerX</th>\n",
       "      <th>middle_fingerY</th>\n",
       "      <th>ring_fingerX</th>\n",
       "      <th>ring_fingerY</th>\n",
       "      <th>pinky_fingerX</th>\n",
       "      <th>pinky_fingerY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>482.841253</td>\n",
       "      <td>659.253359</td>\n",
       "      <td>613.497496</td>\n",
       "      <td>1111.316562</td>\n",
       "      <td>747.461081</td>\n",
       "      <td>1211.838126</td>\n",
       "      <td>844.687581</td>\n",
       "      <td>1323.266506</td>\n",
       "      <td>978.305340</td>\n",
       "      <td>1329.186440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>521.182299</td>\n",
       "      <td>689.849198</td>\n",
       "      <td>663.463116</td>\n",
       "      <td>1154.364109</td>\n",
       "      <td>780.664921</td>\n",
       "      <td>1244.938493</td>\n",
       "      <td>873.840272</td>\n",
       "      <td>1349.051237</td>\n",
       "      <td>1008.606553</td>\n",
       "      <td>1350.400925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>874.109685</td>\n",
       "      <td>1156.880856</td>\n",
       "      <td>696.149170</td>\n",
       "      <td>506.898224</td>\n",
       "      <td>855.762005</td>\n",
       "      <td>440.906525</td>\n",
       "      <td>1007.595539</td>\n",
       "      <td>529.520392</td>\n",
       "      <td>1139.060974</td>\n",
       "      <td>763.899505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>868.652821</td>\n",
       "      <td>1156.651378</td>\n",
       "      <td>682.141542</td>\n",
       "      <td>495.175660</td>\n",
       "      <td>839.159906</td>\n",
       "      <td>429.757535</td>\n",
       "      <td>991.474628</td>\n",
       "      <td>511.134088</td>\n",
       "      <td>1128.865480</td>\n",
       "      <td>755.360603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>224.880040</td>\n",
       "      <td>937.252283</td>\n",
       "      <td>400.737405</td>\n",
       "      <td>447.371006</td>\n",
       "      <td>377.825499</td>\n",
       "      <td>417.031944</td>\n",
       "      <td>421.291202</td>\n",
       "      <td>505.635858</td>\n",
       "      <td>563.122749</td>\n",
       "      <td>647.886872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>609.637856</td>\n",
       "      <td>1094.107032</td>\n",
       "      <td>637.910783</td>\n",
       "      <td>598.148346</td>\n",
       "      <td>581.904829</td>\n",
       "      <td>571.266770</td>\n",
       "      <td>573.114157</td>\n",
       "      <td>563.385725</td>\n",
       "      <td>660.703182</td>\n",
       "      <td>605.419815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D</td>\n",
       "      <td>539.556980</td>\n",
       "      <td>1066.628456</td>\n",
       "      <td>875.156760</td>\n",
       "      <td>507.313013</td>\n",
       "      <td>387.410045</td>\n",
       "      <td>1224.569321</td>\n",
       "      <td>407.440960</td>\n",
       "      <td>1443.077326</td>\n",
       "      <td>526.725352</td>\n",
       "      <td>1501.873255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D</td>\n",
       "      <td>643.790483</td>\n",
       "      <td>1079.744458</td>\n",
       "      <td>1016.610503</td>\n",
       "      <td>396.559060</td>\n",
       "      <td>656.122029</td>\n",
       "      <td>987.788022</td>\n",
       "      <td>626.927733</td>\n",
       "      <td>1071.644902</td>\n",
       "      <td>631.506920</td>\n",
       "      <td>1064.701319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E</td>\n",
       "      <td>896.035314</td>\n",
       "      <td>881.781459</td>\n",
       "      <td>743.320405</td>\n",
       "      <td>661.049306</td>\n",
       "      <td>879.736423</td>\n",
       "      <td>690.903425</td>\n",
       "      <td>1021.958470</td>\n",
       "      <td>736.329317</td>\n",
       "      <td>1127.242684</td>\n",
       "      <td>750.400066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E</td>\n",
       "      <td>862.282872</td>\n",
       "      <td>892.499804</td>\n",
       "      <td>737.999022</td>\n",
       "      <td>667.103231</td>\n",
       "      <td>863.945425</td>\n",
       "      <td>695.670485</td>\n",
       "      <td>1000.038743</td>\n",
       "      <td>738.640010</td>\n",
       "      <td>1118.934393</td>\n",
       "      <td>754.193604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F</td>\n",
       "      <td>487.602532</td>\n",
       "      <td>1166.041851</td>\n",
       "      <td>520.483971</td>\n",
       "      <td>1034.812212</td>\n",
       "      <td>663.428426</td>\n",
       "      <td>379.823029</td>\n",
       "      <td>834.852517</td>\n",
       "      <td>433.140993</td>\n",
       "      <td>1040.631771</td>\n",
       "      <td>659.705758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F</td>\n",
       "      <td>552.064478</td>\n",
       "      <td>1139.820457</td>\n",
       "      <td>596.783817</td>\n",
       "      <td>1017.551064</td>\n",
       "      <td>742.754281</td>\n",
       "      <td>341.581404</td>\n",
       "      <td>926.136136</td>\n",
       "      <td>396.239996</td>\n",
       "      <td>1111.550808</td>\n",
       "      <td>631.874919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G</td>\n",
       "      <td>342.781782</td>\n",
       "      <td>1053.598881</td>\n",
       "      <td>309.269547</td>\n",
       "      <td>668.269694</td>\n",
       "      <td>700.761318</td>\n",
       "      <td>1068.297863</td>\n",
       "      <td>806.248069</td>\n",
       "      <td>1105.961084</td>\n",
       "      <td>900.886893</td>\n",
       "      <td>1163.988352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G</td>\n",
       "      <td>320.062399</td>\n",
       "      <td>1054.865718</td>\n",
       "      <td>275.753677</td>\n",
       "      <td>675.551295</td>\n",
       "      <td>676.814795</td>\n",
       "      <td>1087.255239</td>\n",
       "      <td>790.046573</td>\n",
       "      <td>1132.946014</td>\n",
       "      <td>881.841183</td>\n",
       "      <td>1189.443827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>H</td>\n",
       "      <td>742.654502</td>\n",
       "      <td>1062.175870</td>\n",
       "      <td>377.500534</td>\n",
       "      <td>868.336380</td>\n",
       "      <td>269.881904</td>\n",
       "      <td>1012.861848</td>\n",
       "      <td>814.142227</td>\n",
       "      <td>1423.373222</td>\n",
       "      <td>897.713065</td>\n",
       "      <td>1499.624848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>H</td>\n",
       "      <td>742.526293</td>\n",
       "      <td>1134.011149</td>\n",
       "      <td>394.360423</td>\n",
       "      <td>944.313824</td>\n",
       "      <td>286.925077</td>\n",
       "      <td>1131.565452</td>\n",
       "      <td>829.976320</td>\n",
       "      <td>1525.613904</td>\n",
       "      <td>898.594379</td>\n",
       "      <td>1601.883411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I</td>\n",
       "      <td>586.413562</td>\n",
       "      <td>902.494550</td>\n",
       "      <td>689.216852</td>\n",
       "      <td>1147.725582</td>\n",
       "      <td>832.302630</td>\n",
       "      <td>1281.123281</td>\n",
       "      <td>944.171429</td>\n",
       "      <td>1340.186000</td>\n",
       "      <td>1083.127737</td>\n",
       "      <td>492.315531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I</td>\n",
       "      <td>596.451759</td>\n",
       "      <td>936.009586</td>\n",
       "      <td>688.378215</td>\n",
       "      <td>1174.637079</td>\n",
       "      <td>834.005654</td>\n",
       "      <td>1315.289021</td>\n",
       "      <td>946.469903</td>\n",
       "      <td>1375.979304</td>\n",
       "      <td>1080.031872</td>\n",
       "      <td>513.391793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>J</td>\n",
       "      <td>994.632661</td>\n",
       "      <td>794.810653</td>\n",
       "      <td>985.712945</td>\n",
       "      <td>913.825214</td>\n",
       "      <td>831.093788</td>\n",
       "      <td>981.511295</td>\n",
       "      <td>702.326536</td>\n",
       "      <td>1028.491735</td>\n",
       "      <td>191.535294</td>\n",
       "      <td>704.917133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J</td>\n",
       "      <td>917.050481</td>\n",
       "      <td>854.427814</td>\n",
       "      <td>923.557401</td>\n",
       "      <td>951.494098</td>\n",
       "      <td>768.669307</td>\n",
       "      <td>1023.454070</td>\n",
       "      <td>635.910273</td>\n",
       "      <td>1065.616250</td>\n",
       "      <td>108.722150</td>\n",
       "      <td>771.939516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>K</td>\n",
       "      <td>878.774524</td>\n",
       "      <td>1004.048467</td>\n",
       "      <td>682.174027</td>\n",
       "      <td>537.098646</td>\n",
       "      <td>1150.173783</td>\n",
       "      <td>555.549562</td>\n",
       "      <td>992.927134</td>\n",
       "      <td>1590.162992</td>\n",
       "      <td>1126.125097</td>\n",
       "      <td>1602.932334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>K</td>\n",
       "      <td>990.888715</td>\n",
       "      <td>699.190497</td>\n",
       "      <td>871.472955</td>\n",
       "      <td>355.353713</td>\n",
       "      <td>1343.335271</td>\n",
       "      <td>415.853441</td>\n",
       "      <td>1029.259086</td>\n",
       "      <td>1261.397243</td>\n",
       "      <td>1134.829521</td>\n",
       "      <td>1319.432974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L</td>\n",
       "      <td>270.258546</td>\n",
       "      <td>969.629109</td>\n",
       "      <td>862.645268</td>\n",
       "      <td>264.415443</td>\n",
       "      <td>871.955335</td>\n",
       "      <td>1176.568389</td>\n",
       "      <td>1023.895979</td>\n",
       "      <td>1306.885242</td>\n",
       "      <td>1140.659332</td>\n",
       "      <td>1292.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>L</td>\n",
       "      <td>300.584972</td>\n",
       "      <td>823.637784</td>\n",
       "      <td>847.453237</td>\n",
       "      <td>282.762706</td>\n",
       "      <td>994.454563</td>\n",
       "      <td>1083.225012</td>\n",
       "      <td>1120.365500</td>\n",
       "      <td>1144.571543</td>\n",
       "      <td>1252.633333</td>\n",
       "      <td>1127.049923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>M</td>\n",
       "      <td>994.074047</td>\n",
       "      <td>900.906444</td>\n",
       "      <td>597.222745</td>\n",
       "      <td>1012.333155</td>\n",
       "      <td>710.086465</td>\n",
       "      <td>946.574986</td>\n",
       "      <td>851.649344</td>\n",
       "      <td>960.121751</td>\n",
       "      <td>906.718254</td>\n",
       "      <td>1140.492678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>M</td>\n",
       "      <td>1060.488701</td>\n",
       "      <td>977.945507</td>\n",
       "      <td>800.613523</td>\n",
       "      <td>1043.975234</td>\n",
       "      <td>911.166430</td>\n",
       "      <td>1103.935957</td>\n",
       "      <td>1018.862963</td>\n",
       "      <td>1130.899906</td>\n",
       "      <td>1070.568681</td>\n",
       "      <td>1291.618705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>N</td>\n",
       "      <td>764.513671</td>\n",
       "      <td>890.709937</td>\n",
       "      <td>448.182434</td>\n",
       "      <td>1098.185301</td>\n",
       "      <td>578.284621</td>\n",
       "      <td>1041.364670</td>\n",
       "      <td>695.059419</td>\n",
       "      <td>1289.712906</td>\n",
       "      <td>887.407303</td>\n",
       "      <td>1273.291588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>N</td>\n",
       "      <td>1019.736886</td>\n",
       "      <td>815.629423</td>\n",
       "      <td>629.340768</td>\n",
       "      <td>1036.556840</td>\n",
       "      <td>753.869712</td>\n",
       "      <td>986.648440</td>\n",
       "      <td>880.416572</td>\n",
       "      <td>1238.522053</td>\n",
       "      <td>1066.586733</td>\n",
       "      <td>1230.606318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>O</td>\n",
       "      <td>504.604161</td>\n",
       "      <td>889.560640</td>\n",
       "      <td>600.911021</td>\n",
       "      <td>732.617974</td>\n",
       "      <td>592.916846</td>\n",
       "      <td>770.548224</td>\n",
       "      <td>576.219440</td>\n",
       "      <td>853.330135</td>\n",
       "      <td>627.446890</td>\n",
       "      <td>923.630655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>O</td>\n",
       "      <td>588.484883</td>\n",
       "      <td>918.867707</td>\n",
       "      <td>718.305826</td>\n",
       "      <td>792.911172</td>\n",
       "      <td>723.811865</td>\n",
       "      <td>812.010586</td>\n",
       "      <td>710.003376</td>\n",
       "      <td>873.899519</td>\n",
       "      <td>742.872477</td>\n",
       "      <td>917.759836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P</td>\n",
       "      <td>1093.390465</td>\n",
       "      <td>1191.006184</td>\n",
       "      <td>1317.433596</td>\n",
       "      <td>1098.805904</td>\n",
       "      <td>1195.371985</td>\n",
       "      <td>1396.302342</td>\n",
       "      <td>799.057066</td>\n",
       "      <td>1346.460104</td>\n",
       "      <td>743.568122</td>\n",
       "      <td>1318.561316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P</td>\n",
       "      <td>1123.249173</td>\n",
       "      <td>1177.033424</td>\n",
       "      <td>1399.945378</td>\n",
       "      <td>1128.564119</td>\n",
       "      <td>1506.906033</td>\n",
       "      <td>1105.470538</td>\n",
       "      <td>749.910474</td>\n",
       "      <td>1401.504278</td>\n",
       "      <td>691.720366</td>\n",
       "      <td>1396.404982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q</td>\n",
       "      <td>881.614923</td>\n",
       "      <td>1705.452204</td>\n",
       "      <td>1420.454860</td>\n",
       "      <td>1685.214877</td>\n",
       "      <td>843.198895</td>\n",
       "      <td>1151.910543</td>\n",
       "      <td>846.433878</td>\n",
       "      <td>1089.534998</td>\n",
       "      <td>866.864502</td>\n",
       "      <td>1068.631411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q</td>\n",
       "      <td>921.205878</td>\n",
       "      <td>1696.782589</td>\n",
       "      <td>1428.083420</td>\n",
       "      <td>1656.570792</td>\n",
       "      <td>873.277903</td>\n",
       "      <td>1126.911640</td>\n",
       "      <td>878.400803</td>\n",
       "      <td>1048.324943</td>\n",
       "      <td>906.374931</td>\n",
       "      <td>1022.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>R</td>\n",
       "      <td>922.588289</td>\n",
       "      <td>1058.311701</td>\n",
       "      <td>983.875573</td>\n",
       "      <td>251.600087</td>\n",
       "      <td>901.761591</td>\n",
       "      <td>310.203969</td>\n",
       "      <td>834.213614</td>\n",
       "      <td>1228.761792</td>\n",
       "      <td>951.217353</td>\n",
       "      <td>1320.756674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>R</td>\n",
       "      <td>887.343168</td>\n",
       "      <td>1151.728272</td>\n",
       "      <td>1009.483337</td>\n",
       "      <td>393.437147</td>\n",
       "      <td>927.836478</td>\n",
       "      <td>365.569234</td>\n",
       "      <td>847.429752</td>\n",
       "      <td>1301.788211</td>\n",
       "      <td>943.789542</td>\n",
       "      <td>1398.874521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S</td>\n",
       "      <td>669.002414</td>\n",
       "      <td>935.846746</td>\n",
       "      <td>625.392556</td>\n",
       "      <td>1041.232109</td>\n",
       "      <td>783.500850</td>\n",
       "      <td>1116.036415</td>\n",
       "      <td>913.198590</td>\n",
       "      <td>1189.784527</td>\n",
       "      <td>1047.051668</td>\n",
       "      <td>1199.444056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S</td>\n",
       "      <td>734.279811</td>\n",
       "      <td>966.996372</td>\n",
       "      <td>681.157768</td>\n",
       "      <td>1049.371362</td>\n",
       "      <td>837.711215</td>\n",
       "      <td>1119.686604</td>\n",
       "      <td>967.707992</td>\n",
       "      <td>1194.722772</td>\n",
       "      <td>1101.306081</td>\n",
       "      <td>1215.900540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>T</td>\n",
       "      <td>770.855188</td>\n",
       "      <td>814.460099</td>\n",
       "      <td>679.272652</td>\n",
       "      <td>730.335355</td>\n",
       "      <td>719.558001</td>\n",
       "      <td>1235.737920</td>\n",
       "      <td>792.757928</td>\n",
       "      <td>1392.532587</td>\n",
       "      <td>788.937449</td>\n",
       "      <td>1503.928900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>T</td>\n",
       "      <td>778.581023</td>\n",
       "      <td>744.346976</td>\n",
       "      <td>685.112000</td>\n",
       "      <td>687.301219</td>\n",
       "      <td>743.108571</td>\n",
       "      <td>1180.200458</td>\n",
       "      <td>815.911412</td>\n",
       "      <td>1344.035387</td>\n",
       "      <td>807.601988</td>\n",
       "      <td>1474.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>U</td>\n",
       "      <td>936.833024</td>\n",
       "      <td>1137.932062</td>\n",
       "      <td>785.849214</td>\n",
       "      <td>468.644977</td>\n",
       "      <td>966.744184</td>\n",
       "      <td>417.262435</td>\n",
       "      <td>1000.300646</td>\n",
       "      <td>1394.795060</td>\n",
       "      <td>1119.956493</td>\n",
       "      <td>1420.291185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>U</td>\n",
       "      <td>994.595528</td>\n",
       "      <td>1099.467635</td>\n",
       "      <td>888.696671</td>\n",
       "      <td>415.963769</td>\n",
       "      <td>1035.543323</td>\n",
       "      <td>364.874184</td>\n",
       "      <td>1065.860391</td>\n",
       "      <td>1369.064331</td>\n",
       "      <td>1199.392080</td>\n",
       "      <td>1382.335186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>V</td>\n",
       "      <td>1045.639992</td>\n",
       "      <td>1217.796087</td>\n",
       "      <td>676.551402</td>\n",
       "      <td>388.407648</td>\n",
       "      <td>1217.409015</td>\n",
       "      <td>420.347095</td>\n",
       "      <td>969.985485</td>\n",
       "      <td>1520.046234</td>\n",
       "      <td>1055.632353</td>\n",
       "      <td>1538.791180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>V</td>\n",
       "      <td>1037.346721</td>\n",
       "      <td>1131.267071</td>\n",
       "      <td>680.988073</td>\n",
       "      <td>279.734135</td>\n",
       "      <td>1266.443253</td>\n",
       "      <td>309.719980</td>\n",
       "      <td>991.097808</td>\n",
       "      <td>1458.337069</td>\n",
       "      <td>1100.401759</td>\n",
       "      <td>1472.530365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>W</td>\n",
       "      <td>1066.174150</td>\n",
       "      <td>1069.893599</td>\n",
       "      <td>419.939935</td>\n",
       "      <td>333.265066</td>\n",
       "      <td>798.713744</td>\n",
       "      <td>201.065242</td>\n",
       "      <td>1286.032438</td>\n",
       "      <td>335.106254</td>\n",
       "      <td>1072.826385</td>\n",
       "      <td>1236.441612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>W</td>\n",
       "      <td>1053.582549</td>\n",
       "      <td>1068.703294</td>\n",
       "      <td>422.713846</td>\n",
       "      <td>312.484026</td>\n",
       "      <td>816.843271</td>\n",
       "      <td>179.231048</td>\n",
       "      <td>1279.872537</td>\n",
       "      <td>319.565713</td>\n",
       "      <td>1066.509843</td>\n",
       "      <td>1213.271618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>X</td>\n",
       "      <td>1194.881082</td>\n",
       "      <td>1079.638958</td>\n",
       "      <td>1190.039396</td>\n",
       "      <td>575.874865</td>\n",
       "      <td>1159.950972</td>\n",
       "      <td>1010.683417</td>\n",
       "      <td>1049.127579</td>\n",
       "      <td>1039.627671</td>\n",
       "      <td>1082.579374</td>\n",
       "      <td>996.986330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X</td>\n",
       "      <td>1232.170701</td>\n",
       "      <td>1200.942755</td>\n",
       "      <td>1227.747560</td>\n",
       "      <td>696.599483</td>\n",
       "      <td>1167.807460</td>\n",
       "      <td>1126.237631</td>\n",
       "      <td>1047.461152</td>\n",
       "      <td>1137.772083</td>\n",
       "      <td>1099.888682</td>\n",
       "      <td>1108.893752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Y</td>\n",
       "      <td>475.653172</td>\n",
       "      <td>709.080994</td>\n",
       "      <td>947.812140</td>\n",
       "      <td>1141.872168</td>\n",
       "      <td>1084.021568</td>\n",
       "      <td>1255.906820</td>\n",
       "      <td>1238.360286</td>\n",
       "      <td>1321.192861</td>\n",
       "      <td>1665.088177</td>\n",
       "      <td>582.471848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Y</td>\n",
       "      <td>557.723761</td>\n",
       "      <td>801.852286</td>\n",
       "      <td>1016.381860</td>\n",
       "      <td>1320.224047</td>\n",
       "      <td>1143.713713</td>\n",
       "      <td>1416.741371</td>\n",
       "      <td>1293.825507</td>\n",
       "      <td>1462.543130</td>\n",
       "      <td>1739.653468</td>\n",
       "      <td>746.729076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Z</td>\n",
       "      <td>1219.601631</td>\n",
       "      <td>1255.818605</td>\n",
       "      <td>1510.155439</td>\n",
       "      <td>655.836284</td>\n",
       "      <td>952.609360</td>\n",
       "      <td>1184.281945</td>\n",
       "      <td>1003.906488</td>\n",
       "      <td>1218.145132</td>\n",
       "      <td>1125.193477</td>\n",
       "      <td>1053.278804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Z</td>\n",
       "      <td>1301.294327</td>\n",
       "      <td>1335.387111</td>\n",
       "      <td>1620.371699</td>\n",
       "      <td>732.776701</td>\n",
       "      <td>1037.141085</td>\n",
       "      <td>1233.534455</td>\n",
       "      <td>1100.000858</td>\n",
       "      <td>1290.256500</td>\n",
       "      <td>1244.431496</td>\n",
       "      <td>1149.143577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_type  thumb_fingerX  thumb_fingerY  index_fingerX  index_fingerY  \\\n",
       "0           A     482.841253     659.253359     613.497496    1111.316562   \n",
       "1           A     521.182299     689.849198     663.463116    1154.364109   \n",
       "2           B     874.109685    1156.880856     696.149170     506.898224   \n",
       "3           B     868.652821    1156.651378     682.141542     495.175660   \n",
       "4           C     224.880040     937.252283     400.737405     447.371006   \n",
       "5           C     609.637856    1094.107032     637.910783     598.148346   \n",
       "6           D     539.556980    1066.628456     875.156760     507.313013   \n",
       "7           D     643.790483    1079.744458    1016.610503     396.559060   \n",
       "8           E     896.035314     881.781459     743.320405     661.049306   \n",
       "9           E     862.282872     892.499804     737.999022     667.103231   \n",
       "10          F     487.602532    1166.041851     520.483971    1034.812212   \n",
       "11          F     552.064478    1139.820457     596.783817    1017.551064   \n",
       "12          G     342.781782    1053.598881     309.269547     668.269694   \n",
       "13          G     320.062399    1054.865718     275.753677     675.551295   \n",
       "14          H     742.654502    1062.175870     377.500534     868.336380   \n",
       "15          H     742.526293    1134.011149     394.360423     944.313824   \n",
       "16          I     586.413562     902.494550     689.216852    1147.725582   \n",
       "17          I     596.451759     936.009586     688.378215    1174.637079   \n",
       "18          J     994.632661     794.810653     985.712945     913.825214   \n",
       "19          J     917.050481     854.427814     923.557401     951.494098   \n",
       "20          K     878.774524    1004.048467     682.174027     537.098646   \n",
       "21          K     990.888715     699.190497     871.472955     355.353713   \n",
       "22          L     270.258546     969.629109     862.645268     264.415443   \n",
       "23          L     300.584972     823.637784     847.453237     282.762706   \n",
       "24          M     994.074047     900.906444     597.222745    1012.333155   \n",
       "25          M    1060.488701     977.945507     800.613523    1043.975234   \n",
       "26          N     764.513671     890.709937     448.182434    1098.185301   \n",
       "27          N    1019.736886     815.629423     629.340768    1036.556840   \n",
       "28          O     504.604161     889.560640     600.911021     732.617974   \n",
       "29          O     588.484883     918.867707     718.305826     792.911172   \n",
       "30          P    1093.390465    1191.006184    1317.433596    1098.805904   \n",
       "31          P    1123.249173    1177.033424    1399.945378    1128.564119   \n",
       "32          Q     881.614923    1705.452204    1420.454860    1685.214877   \n",
       "33          Q     921.205878    1696.782589    1428.083420    1656.570792   \n",
       "34          R     922.588289    1058.311701     983.875573     251.600087   \n",
       "35          R     887.343168    1151.728272    1009.483337     393.437147   \n",
       "36          S     669.002414     935.846746     625.392556    1041.232109   \n",
       "37          S     734.279811     966.996372     681.157768    1049.371362   \n",
       "38          T     770.855188     814.460099     679.272652     730.335355   \n",
       "39          T     778.581023     744.346976     685.112000     687.301219   \n",
       "40          U     936.833024    1137.932062     785.849214     468.644977   \n",
       "41          U     994.595528    1099.467635     888.696671     415.963769   \n",
       "42          V    1045.639992    1217.796087     676.551402     388.407648   \n",
       "43          V    1037.346721    1131.267071     680.988073     279.734135   \n",
       "44          W    1066.174150    1069.893599     419.939935     333.265066   \n",
       "45          W    1053.582549    1068.703294     422.713846     312.484026   \n",
       "46          X    1194.881082    1079.638958    1190.039396     575.874865   \n",
       "47          X    1232.170701    1200.942755    1227.747560     696.599483   \n",
       "48          Y     475.653172     709.080994     947.812140    1141.872168   \n",
       "49          Y     557.723761     801.852286    1016.381860    1320.224047   \n",
       "50          Z    1219.601631    1255.818605    1510.155439     655.836284   \n",
       "51          Z    1301.294327    1335.387111    1620.371699     732.776701   \n",
       "\n",
       "    middle_fingerX  middle_fingerY  ring_fingerX  ring_fingerY  pinky_fingerX  \\\n",
       "0       747.461081     1211.838126    844.687581   1323.266506     978.305340   \n",
       "1       780.664921     1244.938493    873.840272   1349.051237    1008.606553   \n",
       "2       855.762005      440.906525   1007.595539    529.520392    1139.060974   \n",
       "3       839.159906      429.757535    991.474628    511.134088    1128.865480   \n",
       "4       377.825499      417.031944    421.291202    505.635858     563.122749   \n",
       "5       581.904829      571.266770    573.114157    563.385725     660.703182   \n",
       "6       387.410045     1224.569321    407.440960   1443.077326     526.725352   \n",
       "7       656.122029      987.788022    626.927733   1071.644902     631.506920   \n",
       "8       879.736423      690.903425   1021.958470    736.329317    1127.242684   \n",
       "9       863.945425      695.670485   1000.038743    738.640010    1118.934393   \n",
       "10      663.428426      379.823029    834.852517    433.140993    1040.631771   \n",
       "11      742.754281      341.581404    926.136136    396.239996    1111.550808   \n",
       "12      700.761318     1068.297863    806.248069   1105.961084     900.886893   \n",
       "13      676.814795     1087.255239    790.046573   1132.946014     881.841183   \n",
       "14      269.881904     1012.861848    814.142227   1423.373222     897.713065   \n",
       "15      286.925077     1131.565452    829.976320   1525.613904     898.594379   \n",
       "16      832.302630     1281.123281    944.171429   1340.186000    1083.127737   \n",
       "17      834.005654     1315.289021    946.469903   1375.979304    1080.031872   \n",
       "18      831.093788      981.511295    702.326536   1028.491735     191.535294   \n",
       "19      768.669307     1023.454070    635.910273   1065.616250     108.722150   \n",
       "20     1150.173783      555.549562    992.927134   1590.162992    1126.125097   \n",
       "21     1343.335271      415.853441   1029.259086   1261.397243    1134.829521   \n",
       "22      871.955335     1176.568389   1023.895979   1306.885242    1140.659332   \n",
       "23      994.454563     1083.225012   1120.365500   1144.571543    1252.633333   \n",
       "24      710.086465      946.574986    851.649344    960.121751     906.718254   \n",
       "25      911.166430     1103.935957   1018.862963   1130.899906    1070.568681   \n",
       "26      578.284621     1041.364670    695.059419   1289.712906     887.407303   \n",
       "27      753.869712      986.648440    880.416572   1238.522053    1066.586733   \n",
       "28      592.916846      770.548224    576.219440    853.330135     627.446890   \n",
       "29      723.811865      812.010586    710.003376    873.899519     742.872477   \n",
       "30     1195.371985     1396.302342    799.057066   1346.460104     743.568122   \n",
       "31     1506.906033     1105.470538    749.910474   1401.504278     691.720366   \n",
       "32      843.198895     1151.910543    846.433878   1089.534998     866.864502   \n",
       "33      873.277903     1126.911640    878.400803   1048.324943     906.374931   \n",
       "34      901.761591      310.203969    834.213614   1228.761792     951.217353   \n",
       "35      927.836478      365.569234    847.429752   1301.788211     943.789542   \n",
       "36      783.500850     1116.036415    913.198590   1189.784527    1047.051668   \n",
       "37      837.711215     1119.686604    967.707992   1194.722772    1101.306081   \n",
       "38      719.558001     1235.737920    792.757928   1392.532587     788.937449   \n",
       "39      743.108571     1180.200458    815.911412   1344.035387     807.601988   \n",
       "40      966.744184      417.262435   1000.300646   1394.795060    1119.956493   \n",
       "41     1035.543323      364.874184   1065.860391   1369.064331    1199.392080   \n",
       "42     1217.409015      420.347095    969.985485   1520.046234    1055.632353   \n",
       "43     1266.443253      309.719980    991.097808   1458.337069    1100.401759   \n",
       "44      798.713744      201.065242   1286.032438    335.106254    1072.826385   \n",
       "45      816.843271      179.231048   1279.872537    319.565713    1066.509843   \n",
       "46     1159.950972     1010.683417   1049.127579   1039.627671    1082.579374   \n",
       "47     1167.807460     1126.237631   1047.461152   1137.772083    1099.888682   \n",
       "48     1084.021568     1255.906820   1238.360286   1321.192861    1665.088177   \n",
       "49     1143.713713     1416.741371   1293.825507   1462.543130    1739.653468   \n",
       "50      952.609360     1184.281945   1003.906488   1218.145132    1125.193477   \n",
       "51     1037.141085     1233.534455   1100.000858   1290.256500    1244.431496   \n",
       "\n",
       "    pinky_fingerY  \n",
       "0     1329.186440  \n",
       "1     1350.400925  \n",
       "2      763.899505  \n",
       "3      755.360603  \n",
       "4      647.886872  \n",
       "5      605.419815  \n",
       "6     1501.873255  \n",
       "7     1064.701319  \n",
       "8      750.400066  \n",
       "9      754.193604  \n",
       "10     659.705758  \n",
       "11     631.874919  \n",
       "12    1163.988352  \n",
       "13    1189.443827  \n",
       "14    1499.624848  \n",
       "15    1601.883411  \n",
       "16     492.315531  \n",
       "17     513.391793  \n",
       "18     704.917133  \n",
       "19     771.939516  \n",
       "20    1602.932334  \n",
       "21    1319.432974  \n",
       "22    1292.219400  \n",
       "23    1127.049923  \n",
       "24    1140.492678  \n",
       "25    1291.618705  \n",
       "26    1273.291588  \n",
       "27    1230.606318  \n",
       "28     923.630655  \n",
       "29     917.759836  \n",
       "30    1318.561316  \n",
       "31    1396.404982  \n",
       "32    1068.631411  \n",
       "33    1022.055984  \n",
       "34    1320.756674  \n",
       "35    1398.874521  \n",
       "36    1199.444056  \n",
       "37    1215.900540  \n",
       "38    1503.928900  \n",
       "39    1474.003792  \n",
       "40    1420.291185  \n",
       "41    1382.335186  \n",
       "42    1538.791180  \n",
       "43    1472.530365  \n",
       "44    1236.441612  \n",
       "45    1213.271618  \n",
       "46     996.986330  \n",
       "47    1108.893752  \n",
       "48     582.471848  \n",
       "49     746.729076  \n",
       "50    1053.278804  \n",
       "51    1149.143577  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read CSV file for Validation or Testing the Model using Pandas\n",
    "df_test = pd.read_csv(\"hands_SIBI_validation.csv\", header=0)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conscious-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put Categorical using Pandas\n",
    "df_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\n",
    "df_train[\"class_type\"] = df_train.class_type.cat.codes\n",
    "\n",
    "df_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\n",
    "df_test[\"class_type\"] = df_test.class_type.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy Label and Feature for training\n",
    "y_train = df_train.pop(\"class_type\")\n",
    "x_train = df_train.copy()\n",
    "\n",
    "y_test = df_test.pop(\"class_type\")\n",
    "x_test = df_test.copy()\n",
    "\n",
    "#Copied Features turn to Array by using NumPy\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "random-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the array shape is 1x2, we must turn it into 1x3 so we can feed it into the model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aquatic-wages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 698.884]\n",
      " [ 319.742]\n",
      " [ 910.552]\n",
      " [ 867.298]\n",
      " [1027.874]\n",
      " [1007.115]\n",
      " [1132.987]\n",
      " [1166.619]\n",
      " [1292.078]\n",
      " [1233.431]]\n",
      "[[ 643.79 ]\n",
      " [1079.744]\n",
      " [1016.611]\n",
      " [ 396.559]\n",
      " [ 656.122]\n",
      " [ 987.788]\n",
      " [ 626.928]\n",
      " [1071.645]\n",
      " [ 631.507]\n",
      " [1064.701]]\n"
     ]
    }
   ],
   "source": [
    "#Check sample train and test features\n",
    "print(x_train[0])\n",
    "print(x_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "operational-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of classes according standard Alphabets\n",
    "num_classes = 26\n",
    "\n",
    "#Using the Keras.Utils to put the label categorically \n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acceptable-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 8, 64)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2, 128)            24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 104,346\n",
      "Trainable params: 104,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN model, Train will be feed to 1 Dimension Convolutional Neural Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(64, kernel_size=3, strides=1, activation=\"relu\", input_shape=x_train.shape[1:3]),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "  tf.keras.layers.Conv1D(128, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2), \n",
    "  # Flatten the results to feed into a DNN\n",
    "  tf.keras.layers.Flatten(), \n",
    "  # 512 neuron hidden layer\n",
    "  tf.keras.layers.Dense(512, activation='relu'), \n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "certified-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 0.0423 - val_accuracy: 0.9808\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1533 - accuracy: 0.9588 - val_loss: 0.0732 - val_accuracy: 0.9808\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1862 - accuracy: 0.9436 - val_loss: 0.0690 - val_accuracy: 0.9615\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2528 - accuracy: 0.9566 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1041 - accuracy: 0.9653 - val_loss: 1.5525 - val_accuracy: 0.8654\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2350 - accuracy: 0.9610 - val_loss: 0.3059 - val_accuracy: 0.9615\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1299 - accuracy: 0.9610 - val_loss: 0.2111 - val_accuracy: 0.9231\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2390 - accuracy: 0.9436 - val_loss: 0.4970 - val_accuracy: 0.8846\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0845 - accuracy: 0.9761 - val_loss: 0.4148 - val_accuracy: 0.9038\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0842 - accuracy: 0.9805 - val_loss: 0.0403 - val_accuracy: 0.9808\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5593 - accuracy: 0.9479 - val_loss: 0.0266 - val_accuracy: 0.9808\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9805 - val_loss: 0.0499 - val_accuracy: 0.9615\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2078 - accuracy: 0.9523 - val_loss: 1.6290 - val_accuracy: 0.8077\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2560 - accuracy: 0.9696 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2993 - accuracy: 0.9436 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0930 - accuracy: 0.9783 - val_loss: 0.0491 - val_accuracy: 0.9808\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0794 - accuracy: 0.9740 - val_loss: 0.1011 - val_accuracy: 0.9615\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0712 - accuracy: 0.9848 - val_loss: 0.0654 - val_accuracy: 0.9615\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3224 - accuracy: 0.9371 - val_loss: 0.2063 - val_accuracy: 0.9808\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0462 - accuracy: 0.9892 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1707 - accuracy: 0.9653 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0714 - accuracy: 0.9805 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0966 - accuracy: 0.9675 - val_loss: 0.1456 - val_accuracy: 0.9615\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1867 - accuracy: 0.9761 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.2679 - val_accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3260 - accuracy: 0.9349 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0533 - val_accuracy: 0.9808\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1941 - accuracy: 0.9718 - val_loss: 2.1237 - val_accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2350 - accuracy: 0.9631 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0548 - accuracy: 0.9761 - val_loss: 0.0248 - val_accuracy: 0.9808\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0450 - accuracy: 0.9892 - val_loss: 0.0741 - val_accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0713 - accuracy: 0.9826 - val_loss: 0.1058 - val_accuracy: 0.9615\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0551 - accuracy: 0.9892 - val_loss: 2.2660e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.9675 - val_loss: 0.2677 - val_accuracy: 0.9423\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0803 - accuracy: 0.9761 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0787 - accuracy: 0.9848 - val_loss: 6.4043e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2996 - accuracy: 0.9610 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 0.9761 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 0.9805 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9826 - val_loss: 0.3186 - val_accuracy: 0.9615\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1057 - accuracy: 0.9718 - val_loss: 3.1953e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0636 - accuracy: 0.9892 - val_loss: 2.4225e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0536 - accuracy: 0.9935 - val_loss: 5.8714e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 9.3907e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.9805 - val_loss: 1.7542 - val_accuracy: 0.8654\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2448 - accuracy: 0.9783 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1486 - accuracy: 0.9718 - val_loss: 2.3735e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 8.2492e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0513 - accuracy: 0.9892 - val_loss: 0.5015 - val_accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3087 - accuracy: 0.9544 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1397 - accuracy: 0.9783 - val_loss: 0.4036 - val_accuracy: 0.9615\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1119 - accuracy: 0.9870 - val_loss: 4.4572e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0458 - accuracy: 0.9913 - val_loss: 4.5244e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 2.6281e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1067 - accuracy: 0.9783 - val_loss: 1.1435e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9826 - val_loss: 0.1819 - val_accuracy: 0.9615\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1832 - accuracy: 0.9544 - val_loss: 0.0419 - val_accuracy: 0.9808\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.9783 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0636 - accuracy: 0.9935 - val_loss: 1.2938e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 6.5769e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0728 - accuracy: 0.9935 - val_loss: 3.0499e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0596 - accuracy: 0.9892 - val_loss: 0.7761 - val_accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1030 - accuracy: 0.9805 - val_loss: 2.4591e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1137 - accuracy: 0.9913 - val_loss: 0.0551 - val_accuracy: 0.9808\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0365 - accuracy: 0.9935 - val_loss: 1.7875e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 6.8241e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0634 - accuracy: 0.9870 - val_loss: 1.3726 - val_accuracy: 0.9615\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2413 - accuracy: 0.9805 - val_loss: 4.5928e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0563 - accuracy: 0.9957 - val_loss: 6.4185e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0711 - accuracy: 0.9826 - val_loss: 0.3674 - val_accuracy: 0.9615\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0520 - accuracy: 0.9935 - val_loss: 2.1045e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 6.1829e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9978 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1887 - accuracy: 0.9718 - val_loss: 1.7581e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 0.9935 - val_loss: 0.0367 - val_accuracy: 0.9808\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 0.2566 - val_accuracy: 0.9615\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0483 - accuracy: 0.9913 - val_loss: 2.3521e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9892 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1354 - accuracy: 0.9826 - val_loss: 0.3293 - val_accuracy: 0.9615\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1069 - accuracy: 0.9761 - val_loss: 2.6538e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1061 - accuracy: 0.9761 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0430 - accuracy: 0.9913 - val_loss: 4.9215e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 1.3761e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9913 - val_loss: 5.2910e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 1.7547e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 0.9696 - val_loss: 1.3792e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0194 - accuracy: 0.9913 - val_loss: 0.3955 - val_accuracy: 0.9615\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1004 - accuracy: 0.9783 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 1.6798e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 8.6625e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9935 - val_loss: 4.9516e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1951 - accuracy: 0.9848 - val_loss: 2.2178e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0776 - accuracy: 0.9848 - val_loss: 9.6774e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 1.0198e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 2.0562e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 2.2838e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9b64529a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model\n",
    "model.fit(x_train, y_train, epochs=100, steps_per_epoch=15, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "illegal-license",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved into model_SIBI.h5\n"
     ]
    }
   ],
   "source": [
    "#Saving the model into H5 system file\n",
    "save_model = \"model_SIBI.h5\"\n",
    "model.save(save_model)\n",
    "print(\"Model Saved into\", save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "european-record",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n",
      "[[[ 892.317]\n",
      "  [ 881.301]\n",
      "  [ 743.465]\n",
      "  [ 666.988]\n",
      "  [ 885.235]\n",
      "  [ 691.533]\n",
      "  [1027.745]\n",
      "  [ 737.426]\n",
      "  [1131.495]\n",
      "  [ 753.244]]]\n"
     ]
    }
   ],
   "source": [
    "#Testing the Model\n",
    "input_test = [[[ 892.317], [ 881.301], \n",
    "               [ 743.465], [ 666.988],\n",
    "               [ 885.235], [ 691.533],\n",
    "               [1027.745], [ 737.426],\n",
    "               [1131.495], [ 753.244]]]\n",
    "input_test = np.array(input_test)\n",
    "input = np.reshape(input_test, (input_test.shape[0], input_test.shape[1], 1))\n",
    "print(input_test.shape)\n",
    "print(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instrumental-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.    0.998 0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.002 0.    0.    0.    0.    0.\n",
      "  0.    0.   ]]\n",
      "WARNING:tensorflow:From <ipython-input-14-ce52a49e73f2>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "#Print the Prediction\n",
    "print(model.predict(input_test))\n",
    "print(model.predict_classes(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expensive-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25\n",
    "}\n",
    "\n",
    "predictions = model.predict_classes(input_test)\n",
    "for alphabets, values in classes.items():\n",
    "    if values == predictions[0] :\n",
    "        print(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-armenia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
