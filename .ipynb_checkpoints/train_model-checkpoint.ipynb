{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "false-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_fingerX</th>\n",
       "      <th>thumb_fingerY</th>\n",
       "      <th>index_fingerX</th>\n",
       "      <th>index_fingerY</th>\n",
       "      <th>middle_fingerX</th>\n",
       "      <th>middle_fingerY</th>\n",
       "      <th>ring_fingerX</th>\n",
       "      <th>ring_fingerY</th>\n",
       "      <th>pinky_fingerX</th>\n",
       "      <th>pinky_fingerY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>701.420128</td>\n",
       "      <td>318.919480</td>\n",
       "      <td>915.017724</td>\n",
       "      <td>875.987053</td>\n",
       "      <td>1033.827782</td>\n",
       "      <td>1007.422090</td>\n",
       "      <td>1137.799859</td>\n",
       "      <td>1162.527680</td>\n",
       "      <td>1299.975634</td>\n",
       "      <td>1230.812311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>738.009572</td>\n",
       "      <td>546.695232</td>\n",
       "      <td>896.438837</td>\n",
       "      <td>982.484698</td>\n",
       "      <td>1015.012383</td>\n",
       "      <td>1089.546204</td>\n",
       "      <td>1108.672738</td>\n",
       "      <td>1195.127249</td>\n",
       "      <td>1244.127035</td>\n",
       "      <td>1195.254564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>649.540782</td>\n",
       "      <td>382.200122</td>\n",
       "      <td>865.426779</td>\n",
       "      <td>934.989333</td>\n",
       "      <td>987.588286</td>\n",
       "      <td>1071.101904</td>\n",
       "      <td>1085.783601</td>\n",
       "      <td>1227.977633</td>\n",
       "      <td>1242.133617</td>\n",
       "      <td>1304.133892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>684.587240</td>\n",
       "      <td>395.731837</td>\n",
       "      <td>797.839999</td>\n",
       "      <td>821.599484</td>\n",
       "      <td>967.001498</td>\n",
       "      <td>907.189965</td>\n",
       "      <td>1098.765850</td>\n",
       "      <td>1031.728745</td>\n",
       "      <td>1269.232035</td>\n",
       "      <td>1040.464640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>678.897142</td>\n",
       "      <td>390.343607</td>\n",
       "      <td>773.604393</td>\n",
       "      <td>815.742195</td>\n",
       "      <td>949.358344</td>\n",
       "      <td>898.147583</td>\n",
       "      <td>1081.417561</td>\n",
       "      <td>1023.652792</td>\n",
       "      <td>1254.388928</td>\n",
       "      <td>1041.034222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_type  thumb_fingerX  thumb_fingerY  index_fingerX  index_fingerY  \\\n",
       "0          A     701.420128     318.919480     915.017724     875.987053   \n",
       "1          A     738.009572     546.695232     896.438837     982.484698   \n",
       "2          A     649.540782     382.200122     865.426779     934.989333   \n",
       "3          A     684.587240     395.731837     797.839999     821.599484   \n",
       "4          A     678.897142     390.343607     773.604393     815.742195   \n",
       "\n",
       "   middle_fingerX  middle_fingerY  ring_fingerX  ring_fingerY  pinky_fingerX  \\\n",
       "0     1033.827782     1007.422090   1137.799859   1162.527680    1299.975634   \n",
       "1     1015.012383     1089.546204   1108.672738   1195.127249    1244.127035   \n",
       "2      987.588286     1071.101904   1085.783601   1227.977633    1242.133617   \n",
       "3      967.001498      907.189965   1098.765850   1031.728745    1269.232035   \n",
       "4      949.358344      898.147583   1081.417561   1023.652792    1254.388928   \n",
       "\n",
       "   pinky_fingerY  \n",
       "0    1230.812311  \n",
       "1    1195.254564  \n",
       "2    1304.133892  \n",
       "3    1040.464640  \n",
       "4    1041.034222  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"hands_SIBI_training.csv\", header=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demonstrated-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_fingerX</th>\n",
       "      <th>thumb_fingerY</th>\n",
       "      <th>index_fingerX</th>\n",
       "      <th>index_fingerY</th>\n",
       "      <th>middle_fingerX</th>\n",
       "      <th>middle_fingerY</th>\n",
       "      <th>ring_fingerX</th>\n",
       "      <th>ring_fingerY</th>\n",
       "      <th>pinky_fingerX</th>\n",
       "      <th>pinky_fingerY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>482.530147</td>\n",
       "      <td>663.602710</td>\n",
       "      <td>618.714333</td>\n",
       "      <td>1108.978033</td>\n",
       "      <td>742.493629</td>\n",
       "      <td>1213.959575</td>\n",
       "      <td>836.013734</td>\n",
       "      <td>1319.635391</td>\n",
       "      <td>970.602274</td>\n",
       "      <td>1320.696831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>527.143121</td>\n",
       "      <td>691.565394</td>\n",
       "      <td>665.788949</td>\n",
       "      <td>1149.155378</td>\n",
       "      <td>780.918658</td>\n",
       "      <td>1242.375493</td>\n",
       "      <td>872.791350</td>\n",
       "      <td>1346.536756</td>\n",
       "      <td>1007.527590</td>\n",
       "      <td>1351.095319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>869.509935</td>\n",
       "      <td>1152.306914</td>\n",
       "      <td>693.085134</td>\n",
       "      <td>513.347089</td>\n",
       "      <td>851.270974</td>\n",
       "      <td>442.188203</td>\n",
       "      <td>1007.714987</td>\n",
       "      <td>524.867892</td>\n",
       "      <td>1139.157057</td>\n",
       "      <td>763.286769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>864.763677</td>\n",
       "      <td>1156.251431</td>\n",
       "      <td>684.375286</td>\n",
       "      <td>496.557355</td>\n",
       "      <td>844.287634</td>\n",
       "      <td>432.770491</td>\n",
       "      <td>994.463921</td>\n",
       "      <td>515.173078</td>\n",
       "      <td>1129.500747</td>\n",
       "      <td>759.229779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>241.097152</td>\n",
       "      <td>942.816019</td>\n",
       "      <td>407.389641</td>\n",
       "      <td>442.306489</td>\n",
       "      <td>375.943720</td>\n",
       "      <td>413.123608</td>\n",
       "      <td>413.292289</td>\n",
       "      <td>486.609697</td>\n",
       "      <td>547.516942</td>\n",
       "      <td>640.499532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_type  thumb_fingerX  thumb_fingerY  index_fingerX  index_fingerY  \\\n",
       "0          A     482.530147     663.602710     618.714333    1108.978033   \n",
       "1          A     527.143121     691.565394     665.788949    1149.155378   \n",
       "2          B     869.509935    1152.306914     693.085134     513.347089   \n",
       "3          B     864.763677    1156.251431     684.375286     496.557355   \n",
       "4          C     241.097152     942.816019     407.389641     442.306489   \n",
       "\n",
       "   middle_fingerX  middle_fingerY  ring_fingerX  ring_fingerY  pinky_fingerX  \\\n",
       "0      742.493629     1213.959575    836.013734   1319.635391     970.602274   \n",
       "1      780.918658     1242.375493    872.791350   1346.536756    1007.527590   \n",
       "2      851.270974      442.188203   1007.714987    524.867892    1139.157057   \n",
       "3      844.287634      432.770491    994.463921    515.173078    1129.500747   \n",
       "4      375.943720      413.123608    413.292289    486.609697     547.516942   \n",
       "\n",
       "   pinky_fingerY  \n",
       "0    1320.696831  \n",
       "1    1351.095319  \n",
       "2     763.286769  \n",
       "3     759.229779  \n",
       "4     640.499532  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"hands_SIBI_validation.csv\", header=0)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quick-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\n",
    "df_train[\"class_type\"] = df_train.class_type.cat.codes\n",
    "\n",
    "df_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\n",
    "df_test[\"class_type\"] = df_test.class_type.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop(\"class_type\")\n",
    "x_train = df_train.copy()\n",
    "\n",
    "y_test = df_test.pop(\"class_type\")\n",
    "x_test = df_test.copy()\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "heavy-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "shaped-threshold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 701.42 ]\n",
      " [ 318.919]\n",
      " [ 915.018]\n",
      " [ 875.987]\n",
      " [1033.828]\n",
      " [1007.422]\n",
      " [1137.8  ]\n",
      " [1162.528]\n",
      " [1299.976]\n",
      " [1230.812]]\n",
      "[[ 892.317]\n",
      " [ 881.301]\n",
      " [ 743.465]\n",
      " [ 666.988]\n",
      " [ 885.235]\n",
      " [ 691.533]\n",
      " [1027.745]\n",
      " [ 737.426]\n",
      " [1131.495]\n",
      " [ 753.244]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(x_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "macro-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 26\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sufficient-berry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 8, 64)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2, 128)            24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 104,346\n",
      "Trainable params: 104,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(64, kernel_size=3, strides=1, activation=\"relu\", input_shape=x_train.shape[1:3]),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "  tf.keras.layers.Conv1D(128, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2), \n",
    "  # Flatten the results to feed into a DNN\n",
    "  tf.keras.layers.Flatten(), \n",
    "  # 512 neuron hidden layer\n",
    "  tf.keras.layers.Dense(512, activation='relu'), \n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "homeless-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 0.1610 - val_accuracy: 0.9600\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.2764 - accuracy: 0.9574 - val_loss: 1.7754 - val_accuracy: 0.7400\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3121 - accuracy: 0.9508 - val_loss: 0.0641 - val_accuracy: 0.9600\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.9967 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 0.9475 - val_loss: 0.5103 - val_accuracy: 0.9400\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3607 - accuracy: 0.9344 - val_loss: 0.1559 - val_accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3062 - accuracy: 0.9594 - val_loss: 1.1164 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2320 - accuracy: 0.9672 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 0.9934 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0608 - accuracy: 0.9875 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1827 - accuracy: 0.9803 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0174 - accuracy: 0.9902 - val_loss: 0.1646 - val_accuracy: 0.9600\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3539 - accuracy: 0.9438 - val_loss: 0.0579 - val_accuracy: 0.9600\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2016 - accuracy: 0.9639 - val_loss: 0.2703 - val_accuracy: 0.9200\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0858 - accuracy: 0.9781 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 9.2318e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.2636 - val_accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9875 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0572 - accuracy: 0.9902 - val_loss: 0.0810 - val_accuracy: 0.9600\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2706 - accuracy: 0.9508 - val_loss: 1.9473 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3515 - accuracy: 0.9688 - val_loss: 0.3918 - val_accuracy: 0.9200\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1821 - accuracy: 0.9705 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0247 - accuracy: 0.9902 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0140 - accuracy: 0.9902 - val_loss: 0.6624 - val_accuracy: 0.9400\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4804 - accuracy: 0.9500 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.6974e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0465 - accuracy: 0.9869 - val_loss: 7.7518e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.4368e-04 - accuracy: 1.0000 - val_loss: 6.7421e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.9752e-04 - accuracy: 1.0000 - val_loss: 2.9230e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2.5795e-04 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9400\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3478 - accuracy: 0.9438 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9967 - val_loss: 4.6237e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 8.0730e-04 - accuracy: 1.0000 - val_loss: 5.1083e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7975e-04 - accuracy: 1.0000 - val_loss: 3.6694e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.7060e-04 - accuracy: 1.0000 - val_loss: 1.9549e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3371e-04 - accuracy: 1.0000 - val_loss: 1.7028e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 7.9626e-05 - accuracy: 1.0000 - val_loss: 1.3657e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.2997e-05 - accuracy: 1.0000 - val_loss: 9.4689e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.9266 - val_accuracy: 0.7200\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8663 - accuracy: 0.9311 - val_loss: 7.3228e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.5363e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 6.0227e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3757e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 2.4857e-04 - accuracy: 1.0000 - val_loss: 8.4828e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.9377e-04 - accuracy: 1.0000 - val_loss: 6.5561e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 9.8965e-05 - accuracy: 1.0000 - val_loss: 5.5030e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2551 - accuracy: 0.9625 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 6.6547e-04 - accuracy: 1.0000 - val_loss: 6.9335e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.0798e-05 - accuracy: 1.0000 - val_loss: 6.3233e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.6611e-05 - accuracy: 1.0000 - val_loss: 5.2627e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.7853e-05 - accuracy: 1.0000 - val_loss: 5.2614e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.7437e-05 - accuracy: 1.0000 - val_loss: 5.6315e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.1596e-04 - accuracy: 1.0000 - val_loss: 3.3617e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.7546e-05 - accuracy: 1.0000 - val_loss: 3.0726e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.9785 - val_accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3685 - accuracy: 0.9672 - val_loss: 5.9882e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 0.9969 - val_loss: 1.8965 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2727 - accuracy: 0.9803 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 9.7437e-04 - accuracy: 1.0000 - val_loss: 1.5022e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.8023e-05 - accuracy: 1.0000 - val_loss: 1.1358e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.6941e-05 - accuracy: 1.0000 - val_loss: 8.3518e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2641e-05 - accuracy: 1.0000 - val_loss: 7.6836e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.2937e-05 - accuracy: 1.0000 - val_loss: 5.6108e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 8.6088e-06 - accuracy: 1.0000 - val_loss: 4.8452e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 8.7475e-06 - accuracy: 1.0000 - val_loss: 4.0453e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.1073e-06 - accuracy: 1.0000 - val_loss: 3.2686e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.4494e-06 - accuracy: 1.0000 - val_loss: 2.8851e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.0349e-06 - accuracy: 1.0000 - val_loss: 4.2119e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.8406e-06 - accuracy: 1.0000 - val_loss: 9.2804e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5063e-06 - accuracy: 1.0000 - val_loss: 1.3351e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0833e-06 - accuracy: 1.0000 - val_loss: 2.5921e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 7.1173e-07 - accuracy: 1.0000 - val_loss: 8.3101e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.3580e-07 - accuracy: 1.0000 - val_loss: 6.5033e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 2.6487e-07 - accuracy: 1.0000 - val_loss: 7.4280e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2908 - accuracy: 0.9607 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 8.4282e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 7.3121e-04 - accuracy: 1.0000 - val_loss: 5.2617e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.6235e-05 - accuracy: 1.0000 - val_loss: 4.2914e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 7.6271e-05 - accuracy: 1.0000 - val_loss: 4.3939e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0779e-05 - accuracy: 1.0000 - val_loss: 3.5738e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.3643e-06 - accuracy: 1.0000 - val_loss: 2.5105e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.8978e-06 - accuracy: 1.0000 - val_loss: 3.4141e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 6.8923e-06 - accuracy: 1.0000 - val_loss: 1.7237e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.3899e-06 - accuracy: 1.0000 - val_loss: 2.2888e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.7700e-06 - accuracy: 1.0000 - val_loss: 9.3221e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7508e-06 - accuracy: 1.0000 - val_loss: 1.3614e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2.5710e-06 - accuracy: 1.0000 - val_loss: 6.5803e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.8598e-07 - accuracy: 1.0000 - val_loss: 5.1260e-07 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.9526e-07 - accuracy: 1.0000 - val_loss: 4.2438e-07 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.9861e-07 - accuracy: 1.0000 - val_loss: 3.2663e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.8303e-07 - accuracy: 1.0000 - val_loss: 2.8372e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0170e-07 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2624e-07 - accuracy: 1.0000 - val_loss: 1.5259e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12214180400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, steps_per_epoch=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "superior-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = \"model_SIBI.h5\"\n",
    "model.save(save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "superb-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n",
      "[[[ 892.317]\n",
      "  [ 881.301]\n",
      "  [ 743.465]\n",
      "  [ 666.988]\n",
      "  [ 885.235]\n",
      "  [ 691.533]\n",
      "  [1027.745]\n",
      "  [ 737.426]\n",
      "  [1131.495]\n",
      "  [ 753.244]]]\n"
     ]
    }
   ],
   "source": [
    "input_test = [[[ 892.317], [ 881.301], \n",
    "               [ 743.465], [ 666.988],\n",
    "               [ 885.235], [ 691.533],\n",
    "               [1027.745], [ 737.426],\n",
    "               [1131.495], [ 753.244]]]\n",
    "input_test = np.array(input_test)\n",
    "input = np.reshape(input_test, (input_test.shape[0], input_test.shape[1], 1))\n",
    "print(input_test.shape)\n",
    "print(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coupled-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(input_test))\n",
    "print(model.predict_classes(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "published-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25\n",
    "}\n",
    "\n",
    "predictions = model.predict_classes(input_test)\n",
    "for alphabets, values in classes.items():\n",
    "    if values == predictions[0] :\n",
    "        print(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-scenario",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
